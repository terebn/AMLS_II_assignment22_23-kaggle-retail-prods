{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-22 20:46:04.401210: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from config import Config\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import Config\n",
    "\n",
    "data_path = Config.data_path\n",
    "out_path = Config.out_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data for text and images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-22 20:51:43.725087: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from src.preprocess import get_image_text_label_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 33583 files belonging to 21 classes.\n",
      "Using 26867 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-22 20:51:47.589839: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-22 20:51:47.593807: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-22 20:51:47.593928: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-22 20:51:47.594305: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-22 20:51:47.595096: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-22 20:51:47.595161: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-22 20:51:47.595200: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-22 20:51:48.601548: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-22 20:51:48.601748: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-22 20:51:48.601759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-03-22 20:51:48.601836: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-22 20:51:48.601906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5909 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:08:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 33583 files belonging to 21 classes.\n",
      "Using 6716 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train, val, class_names = get_image_text_label_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Val sets\n",
    "\n",
    "train_images = train['images'] / 255.0\n",
    "val_images = val['images'] / 255.0\n",
    "\n",
    "train_lables =  train['labels']\n",
    "val_labels = val['labels']\n",
    "\n",
    "train_text = train['text']\n",
    "val_text = val['text']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_embeddings(images):\n",
    "    \"\"\"\n",
    "    Loads a trained Keras CNN model and produces embeddings for the given numpy.ndarray of images.\n",
    "\n",
    "    Args:\n",
    "        images (numpy.ndarray): A numpy array of images for which embeddings are to be produced.\n",
    "\n",
    "    Returns:\n",
    "        embeddings (numpy.ndarray): A numpy array of embeddings for the given images.\n",
    "\n",
    "    \"\"\"\n",
    "    # Load the saved Keras model from the 'cnn' folder.\n",
    "    model = tf.keras.models.load_model(Config.model_path / 'cnn')\n",
    "\n",
    "    # Define a new model that outputs embeddings for the given input images.\n",
    "    embedding_model = tf.keras.models.Model(inputs=model.input, outputs=model.layers[-2].output)\n",
    "\n",
    "    # Produce embeddings for the input images using the embedding model.\n",
    "    embeddings = embedding_model.predict(images)\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 86ms/step\n"
     ]
    }
   ],
   "source": [
    "train_image_embeddings = get_image_embeddings(train_images[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.7830307 , -0.17228794,  0.04804261, ..., -0.9839945 ,\n",
       "        -0.48064113, -1.2190042 ],\n",
       "       [-1.788084  , -0.1884675 ,  0.04804261, ..., -0.98718786,\n",
       "        -0.48890972, -1.2072499 ],\n",
       "       [-1.7786212 , -0.17712045,  0.04804261, ..., -0.9820397 ,\n",
       "        -0.47511935, -1.2187872 ],\n",
       "       ...,\n",
       "       [-1.7837408 , -0.17538548,  0.04804261, ..., -0.9876039 ,\n",
       "        -0.48491168, -1.217246  ],\n",
       "       [-1.7853229 , -0.18212628,  0.04804261, ..., -0.987591  ,\n",
       "        -0.48899412, -1.2102402 ],\n",
       "       [-1.7825965 , -0.18086481,  0.04804261, ..., -0.9878912 ,\n",
       "        -0.4895444 , -1.2093325 ]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image_embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = hub.load('https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1')\n",
    "encoder = hub.load('https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TUNGSTEN SOLDER PICK WITH HANDLE Solder Pick for picking up molten solder when making jewelry',\n",
       "       'Galt Toys Sponge Painting Contents: 4 x 22ml pots of paint, 8 sponge shapes, sponge roller, sponge brush, 4 stencils, 3 x A3 paper sheets, 3 cards and envelopes, 5 gift tags.',\n",
       "       'Fiskars Deckle Paper Scissor Edger (12-92187897 ) Fiskars Classic Paper Edgers are making a come back in the marketplace.  Add decorative edges to paper with ease.',\n",
       "       'Staedtler(R) GeoStudent Compass Student compass draws circles up to 8\" in diameter. Design offers easy-to-handle design and sturdy, all-metal construction. Centerwheel offers extremely fine settings. Compass includes 2mm lead refills.',\n",
       "       'T.S. Shure Woodburning Creations Kit Wood Burning Creations'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_text[0:5].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_embeddings(text, trainable=False):\n",
    "    \"\"\"\n",
    "    Loads BERT and produces embeddings for the given numpy.ndarray of text.\n",
    "\n",
    "    Args:\n",
    "        text (numpy.ndarray): A numpy array of text for which embeddings are to be produced.\n",
    "\n",
    "    Returns:\n",
    "        embeddings (numpy.ndarray): A numpy array of embeddings for the given text.\n",
    "\n",
    "    \"\"\"\n",
    "    # Load the BERT preprocessor and model.\n",
    "    preprocess = hub.load('https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1')\n",
    "    encoder = hub.load('https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3')\n",
    "    \n",
    "    # Set the trainability of the base encoder.\n",
    "    encoder.trainable = trainable\n",
    "\n",
    "    input = preprocess(text)\n",
    "    embeddings = encoder(input)[\"pooled_output\"]\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([5, 768])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_text_embeddings(val_text[0:5].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 768), dtype=float32, numpy=\n",
       "array([[-0.853229  , -0.4701246 , -0.9118326 , ..., -0.9242439 ,\n",
       "        -0.6083519 ,  0.75898755],\n",
       "       [-0.63061345, -0.48536488, -0.9875117 , ..., -0.8972233 ,\n",
       "        -0.64699835,  0.68899375],\n",
       "       [-0.80999315, -0.34002525, -0.9851131 , ..., -0.9558615 ,\n",
       "        -0.572348  ,  0.5664147 ],\n",
       "       [-0.8411222 , -0.4495623 , -0.9691123 , ..., -0.90381736,\n",
       "        -0.6503354 ,  0.6637933 ],\n",
       "       [-0.91697705, -0.6176196 , -0.98456764, ..., -0.927929  ,\n",
       "        -0.71662486,  0.8328254 ]], dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_text_embeddings(val_text[0:5].to_numpy(), trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(out_path / \"train_embeddings.pkl\", \"wb\") as fOut:\n",
    "    pickle.dump({'sentences': train_text[~train_text.isna()].tolist(), 'embeddings': pooled_output},fOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_embeddings(\n",
    "    embeddings, num_projection_layers, projection_dims, dropout_rate\n",
    "):\n",
    "    projected_embeddings = layers.Dense(units=projection_dims)(embeddings)\n",
    "    for _ in range(num_projection_layers):\n",
    "        x = tf.nn.gelu(projected_embeddings)\n",
    "        x = layers.Dense(projection_dims)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "        x = layers.Add()([projected_embeddings, x])\n",
    "        projected_embeddings = layers.LayerNormalization()(x)\n",
    "    return projected_embeddings\n",
    "\n",
    "\n",
    "def create_text_encoder(preprocess, bert,\n",
    "    num_projection_layers, projection_dims, dropout_rate, trainable=False\n",
    "):\n",
    "    # Set the trainability of the base encoder.\n",
    "    bert.trainable = trainable\n",
    "    # Receive the text as inputs.\n",
    "    inputs = layers.Input(shape=(), dtype=tf.string, name=\"text_input\")\n",
    "    # Preprocess the text.\n",
    "    bert_inputs = preprocess(inputs)\n",
    "    # Generate embeddings for the preprocessed text using the BERT model.\n",
    "    embeddings = bert(bert_inputs)[\"pooled_output\"]\n",
    "    # Project the embeddings produced by the model.\n",
    "    outputs = project_embeddings(\n",
    "        embeddings, num_projection_layers, projection_dims, dropout_rate\n",
    "    )\n",
    "    # Create the text encoder model.\n",
    "    return keras.Model(inputs, outputs, name=\"text_encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "You are passing KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.string, name='text_input'), name='text_input', description=\"created by layer 'text_input'\"), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/teresabono/Documents/UCL/Task/kaggle-retail-prods/experminet_dual_encoder.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/teresabono/Documents/UCL/Task/kaggle-retail-prods/experminet_dual_encoder.ipynb#X56sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m text_encoder \u001b[39m=\u001b[39m create_text_encoder(preprocess\u001b[39m=\u001b[39;49mpreprocess, bert\u001b[39m=\u001b[39;49mencoder,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/teresabono/Documents/UCL/Task/kaggle-retail-prods/experminet_dual_encoder.ipynb#X56sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     num_projection_layers\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, projection_dims\u001b[39m=\u001b[39;49m\u001b[39m256\u001b[39;49m, dropout_rate\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/teresabono/Documents/UCL/Task/kaggle-retail-prods/experminet_dual_encoder.ipynb#X56sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m )\n",
      "\u001b[1;32m/Users/teresabono/Documents/UCL/Task/kaggle-retail-prods/experminet_dual_encoder.ipynb Cell 13\u001b[0m in \u001b[0;36mcreate_text_encoder\u001b[0;34m(preprocess, bert, num_projection_layers, projection_dims, dropout_rate, trainable)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/teresabono/Documents/UCL/Task/kaggle-retail-prods/experminet_dual_encoder.ipynb#X56sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m inputs \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mInput(shape\u001b[39m=\u001b[39m(), dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mstring, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtext_input\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/teresabono/Documents/UCL/Task/kaggle-retail-prods/experminet_dual_encoder.ipynb#X56sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Preprocess the text.\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/teresabono/Documents/UCL/Task/kaggle-retail-prods/experminet_dual_encoder.ipynb#X56sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m bert_inputs \u001b[39m=\u001b[39m preprocess(inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/teresabono/Documents/UCL/Task/kaggle-retail-prods/experminet_dual_encoder.ipynb#X56sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Generate embeddings for the preprocessed text using the BERT model.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/teresabono/Documents/UCL/Task/kaggle-retail-prods/experminet_dual_encoder.ipynb#X56sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m embeddings \u001b[39m=\u001b[39m bert(bert_inputs)[\u001b[39m\"\u001b[39m\u001b[39mpooled_output\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/re-prods/lib/python3.10/site-packages/tensorflow/python/saved_model/load.py:732\u001b[0m, in \u001b[0;36m_call_attribute\u001b[0;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_attribute\u001b[39m(instance, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 732\u001b[0m   \u001b[39mreturn\u001b[39;00m instance\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/re-prods/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/re-prods/lib/python3.10/site-packages/keras/engine/keras_tensor.py:283\u001b[0m, in \u001b[0;36mKerasTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 283\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    284\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mYou are passing \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, an intermediate Keras symbolic \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minput/output, to a TF API that does not allow registering custom \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdispatchers, such as `tf.cond`, `tf.function`, gradient tapes, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    287\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mor `tf.map_fn`. Keras Functional model construction only supports \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTF API calls that *do* support dispatching, such as `tf.math.add` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    289\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mor `tf.reshape`. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    290\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mOther APIs cannot be called directly on symbolic Keras\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    291\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minputs/outputs. You can work around \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    292\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mthis limitation by putting the operation in a custom Keras layer \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    293\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`call` and calling that layer \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    294\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mon this symbolic input/output.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    295\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: You are passing KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.string, name='text_input'), name='text_input', description=\"created by layer 'text_input'\"), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output."
     ]
    }
   ],
   "source": [
    "text_encoder = create_text_encoder(preprocess=preprocess, bert=encoder,\n",
    "    num_projection_layers=1, projection_dims=256, dropout_rate=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_embeddings(\n",
    "    embeddings, num_projection_layers, projection_dims, dropout_rate\n",
    "):\n",
    "    projected_embeddings = layers.Dense(units=projection_dims)(embeddings)\n",
    "    for _ in range(num_projection_layers):\n",
    "        x = tf.nn.gelu(projected_embeddings)\n",
    "        x = layers.Dense(projection_dims)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "        x = layers.Add()([projected_embeddings, x])\n",
    "        projected_embeddings = layers.LayerNormalization()(x)\n",
    "    return projected_embeddings\n",
    "\n",
    "\n",
    "def create_text_encoder(preprocess, encoder,\n",
    "    num_projection_layers, projection_dims, dropout_rate, trainable=False\n",
    "):\n",
    "    # Load the BERT preprocessing module.\n",
    "    preprocess = hub.KerasLayer(\n",
    "        \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2\",\n",
    "        name=\"text_preprocessing\",\n",
    "    )\n",
    "    # Load the pre-trained BERT model to be used as the base encoder.\n",
    "    bert = hub.KerasLayer(\n",
    "        \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\",\n",
    "        \"bert\",\n",
    "    )\n",
    "    # Set the trainability of the base encoder.\n",
    "    bert.trainable = trainable\n",
    "    # Receive the text as inputs.\n",
    "    inputs = layers.Input(shape=(), dtype=tf.string, name=\"text_input\")\n",
    "    # Preprocess the text.\n",
    "    bert_inputs = preprocess(inputs)\n",
    "    # Generate embeddings for the preprocessed text using the BERT model.\n",
    "    embeddings = bert(bert_inputs)[\"pooled_output\"]\n",
    "    # Project the embeddings produced by the model.\n",
    "    outputs = project_embeddings(\n",
    "        embeddings, num_projection_layers, projection_dims, dropout_rate\n",
    "    )\n",
    "    # Create the text encoder model.\n",
    "    return keras.Model(inputs, outputs, name=\"text_encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected `trainable` argument to be a boolean, but got: bert",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/teresabono/Documents/UCL/Task/kaggle-retail-prods/experminet_dual_encoder.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/teresabono/Documents/UCL/Task/kaggle-retail-prods/experminet_dual_encoder.ipynb#X50sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m text_encoder \u001b[39m=\u001b[39m create_text_encoder(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/teresabono/Documents/UCL/Task/kaggle-retail-prods/experminet_dual_encoder.ipynb#X50sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     num_projection_layers\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, projection_dims\u001b[39m=\u001b[39;49m\u001b[39m256\u001b[39;49m, dropout_rate\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/teresabono/Documents/UCL/Task/kaggle-retail-prods/experminet_dual_encoder.ipynb#X50sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m )\n",
      "\u001b[1;32m/Users/teresabono/Documents/UCL/Task/kaggle-retail-prods/experminet_dual_encoder.ipynb Cell 13\u001b[0m in \u001b[0;36mcreate_text_encoder\u001b[0;34m(num_projection_layers, projection_dims, dropout_rate, trainable)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/teresabono/Documents/UCL/Task/kaggle-retail-prods/experminet_dual_encoder.ipynb#X50sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m preprocess \u001b[39m=\u001b[39m hub\u001b[39m.\u001b[39mKerasLayer(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/teresabono/Documents/UCL/Task/kaggle-retail-prods/experminet_dual_encoder.ipynb#X50sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mhttps://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/teresabono/Documents/UCL/Task/kaggle-retail-prods/experminet_dual_encoder.ipynb#X50sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtext_preprocessing\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/teresabono/Documents/UCL/Task/kaggle-retail-prods/experminet_dual_encoder.ipynb#X50sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/teresabono/Documents/UCL/Task/kaggle-retail-prods/experminet_dual_encoder.ipynb#X50sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# Load the pre-trained BERT model to be used as the base encoder.\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/teresabono/Documents/UCL/Task/kaggle-retail-prods/experminet_dual_encoder.ipynb#X50sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m bert \u001b[39m=\u001b[39m hub\u001b[39m.\u001b[39;49mKerasLayer(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/teresabono/Documents/UCL/Task/kaggle-retail-prods/experminet_dual_encoder.ipynb#X50sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mhttps://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/teresabono/Documents/UCL/Task/kaggle-retail-prods/experminet_dual_encoder.ipynb#X50sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mbert\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/teresabono/Documents/UCL/Task/kaggle-retail-prods/experminet_dual_encoder.ipynb#X50sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/teresabono/Documents/UCL/Task/kaggle-retail-prods/experminet_dual_encoder.ipynb#X50sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# Set the trainability of the base encoder.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/teresabono/Documents/UCL/Task/kaggle-retail-prods/experminet_dual_encoder.ipynb#X50sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m bert\u001b[39m.\u001b[39mtrainable \u001b[39m=\u001b[39m trainable\n",
      "File \u001b[0;32m~/miniconda3/envs/re-prods/lib/python3.10/site-packages/tensorflow_hub/keras_layer.py:176\u001b[0m, in \u001b[0;36mKerasLayer.__init__\u001b[0;34m(self, handle, trainable, arguments, _sentinel, tags, signature, signature_outputs_as_dict, output_key, output_shape, load_options, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callable \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_callable()\n\u001b[1;32m    175\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_training_argument \u001b[39m=\u001b[39m func_has_training_argument(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callable)\n\u001b[0;32m--> 176\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setup_layer(trainable, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/re-prods/lib/python3.10/site-packages/tensorflow_hub/keras_layer.py:181\u001b[0m, in \u001b[0;36mKerasLayer._setup_layer\u001b[0;34m(self, trainable, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[39m\"\"\"Constructs keras layer with relevant weights and losses.\"\"\"\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[39m# Initialize an empty layer, then add_weight() etc. as needed.\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(trainable\u001b[39m=\u001b[39;49mtrainable, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    183\u001b[0m \u001b[39m# Add trainable and non-trainable weights from the callable.\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func, \u001b[39m\"\u001b[39m\u001b[39mtrainable_variables\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/re-prods/lib/python3.10/site-packages/tensorflow/python/trackable/base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    206\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/re-prods/lib/python3.10/site-packages/keras/engine/base_layer.py:352\u001b[0m, in \u001b[0;36mLayer.__init__\u001b[0;34m(self, trainable, name, dtype, dynamic, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[39m# Mutable properties\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \u001b[39m# Indicates whether the layer's weights are updated during training\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \u001b[39m# and whether the layer's updates are run during training.\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\n\u001b[1;32m    346\u001b[0m     \u001b[39misinstance\u001b[39m(trainable, \u001b[39mbool\u001b[39m)\n\u001b[1;32m    347\u001b[0m     \u001b[39mor\u001b[39;00m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m     )\n\u001b[1;32m    351\u001b[0m ):\n\u001b[0;32m--> 352\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    353\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mExpected `trainable` argument to be a boolean, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    354\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got: \u001b[39m\u001b[39m{\u001b[39;00mtrainable\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    355\u001b[0m     )\n\u001b[1;32m    356\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_trainable \u001b[39m=\u001b[39m trainable\n\u001b[1;32m    357\u001b[0m \u001b[39m# A stateful layer is a layer whose updates are run during inference\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[39m# too, for instance stateful RNNs.\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected `trainable` argument to be a boolean, but got: bert"
     ]
    }
   ],
   "source": [
    "text_encoder = create_text_encoder(\n",
    "    num_projection_layers=1, projection_dims=256, dropout_rate=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/teresabono/Documents/UCL/Task/kaggle-retail-prods/experminet_dual_encoder.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/teresabono/Documents/UCL/Task/kaggle-retail-prods/experminet_dual_encoder.ipynb#X51sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m text_encoder\u001b[39m.\u001b[39msummary()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text_encoder' is not defined"
     ]
    }
   ],
   "source": [
    "text_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model\n",
    "base_model = tf.keras.applications.InceptionV3(weights='imagenet', include_top=False, input_shape=(Config.IMG_HEIGHT, Config.IMG_WIDTH, 3))\n",
    "\n",
    "# Freeze the layers in the pre-trained model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new output layer with the number of classes equal to your problem\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "predictions = Dense(n_classes, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "# Create the fine-tuned model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 49, 49, 32)   864         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 49, 49, 32)  96          ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 49, 49, 32)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 47, 47, 32)   9216        ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 47, 47, 32)  96          ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 47, 47, 32)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 47, 47, 64)   18432       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 47, 47, 64)  192         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 47, 47, 64)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 23, 23, 64)   0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 23, 23, 80)   5120        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 23, 23, 80)  240         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 23, 23, 80)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 21, 21, 192)  138240      ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 21, 21, 192)  576        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 21, 21, 192)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 10, 10, 192)  0          ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 10, 10, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 10, 10, 64)  192         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 10, 10, 64)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 10, 10, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 10, 10, 96)   55296       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 10, 10, 48)  144         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 10, 10, 96)  288         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 10, 10, 48)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 10, 10, 96)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 10, 10, 192)  0          ['max_pooling2d_1[0][0]']        \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 10, 10, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 10, 10, 64)   76800       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 10, 10, 96)   82944       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 10, 10, 32)   6144        ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 10, 10, 64)  192         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 10, 10, 64)  192         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 10, 10, 96)  288         ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 10, 10, 32)  96          ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 10, 10, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 10, 10, 64)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 10, 10, 96)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 10, 10, 32)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 10, 10, 256)  0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_7[0][0]',           \n",
      "                                                                  'activation_10[0][0]',          \n",
      "                                                                  'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 10, 10, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 10, 10, 64)  192         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 10, 10, 64)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 10, 10, 48)   12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 10, 10, 96)   55296       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 10, 10, 48)  144         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 10, 10, 96)  288         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 10, 10, 48)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 10, 10, 96)   0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 10, 10, 256)  0          ['mixed0[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 10, 10, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 10, 10, 64)   76800       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 10, 10, 96)   82944       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 10, 10, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 10, 10, 64)  192         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 10, 10, 64)  192         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 10, 10, 96)  288         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 10, 10, 64)  192         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 10, 10, 64)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 10, 10, 64)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 10, 10, 96)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 10, 10, 64)   0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 10, 10, 288)  0           ['activation_12[0][0]',          \n",
      "                                                                  'activation_14[0][0]',          \n",
      "                                                                  'activation_17[0][0]',          \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 10, 10, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 10, 10, 64)  192         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 10, 10, 64)   0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 10, 10, 48)   13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 10, 10, 96)   55296       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 10, 10, 48)  144         ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 10, 10, 96)  288         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 10, 10, 48)   0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 10, 10, 96)   0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 10, 10, 288)  0          ['mixed1[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 10, 10, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 10, 10, 64)   76800       ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 10, 10, 96)   82944       ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 10, 10, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 10, 10, 64)  192         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 10, 10, 64)  192         ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 10, 10, 96)  288         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 10, 10, 64)  192         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 10, 10, 64)   0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 10, 10, 64)   0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 10, 10, 96)   0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 10, 10, 64)   0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 10, 10, 288)  0           ['activation_19[0][0]',          \n",
      "                                                                  'activation_21[0][0]',          \n",
      "                                                                  'activation_24[0][0]',          \n",
      "                                                                  'activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 10, 10, 64)   18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 10, 10, 64)  192         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 10, 10, 64)   0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 10, 10, 96)   55296       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 10, 10, 96)  288         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 10, 10, 96)   0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 4, 4, 384)    995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 4, 4, 96)     82944       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 4, 4, 384)   1152        ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 4, 4, 96)    288         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 4, 4, 384)    0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 4, 4, 96)     0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 4, 4, 288)   0           ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 4, 4, 768)    0           ['activation_26[0][0]',          \n",
      "                                                                  'activation_29[0][0]',          \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 4, 4, 128)    98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 4, 4, 128)   384         ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 4, 4, 128)    114688      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 4, 4, 128)   384         ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 4, 4, 128)    98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 4, 4, 128)    114688      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 4, 4, 128)   384         ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 4, 4, 128)   384         ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 4, 4, 128)    114688      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 4, 4, 128)    114688      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 4, 4, 128)   384         ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 4, 4, 128)   384         ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, 4, 4, 768)   0           ['mixed3[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 4, 4, 192)    147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 4, 4, 192)    172032      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 4, 4, 192)    172032      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 4, 4, 192)    147456      ['average_pooling2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 4, 4, 192)   576         ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 4, 4, 192)   576         ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 4, 4, 192)   576         ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 4, 4, 192)   576         ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 4, 4, 192)    0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 4, 4, 192)    0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 4, 4, 192)    0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 4, 4, 192)    0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 4, 4, 768)    0           ['activation_30[0][0]',          \n",
      "                                                                  'activation_33[0][0]',          \n",
      "                                                                  'activation_38[0][0]',          \n",
      "                                                                  'activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 4, 4, 160)    122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 4, 4, 160)   480         ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 4, 4, 160)    0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 4, 4, 160)    179200      ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 4, 4, 160)   480         ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 4, 4, 160)    0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 4, 4, 160)    122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 4, 4, 160)    179200      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 4, 4, 160)   480         ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 4, 4, 160)   480         ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 4, 4, 160)    0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 4, 4, 160)    0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 4, 4, 160)    179200      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 4, 4, 160)    179200      ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 4, 4, 160)   480         ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 4, 4, 160)   480         ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 4, 4, 160)    0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 4, 4, 160)    0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (AveragePo  (None, 4, 4, 768)   0           ['mixed4[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 4, 4, 192)    147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 4, 4, 192)    215040      ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 4, 4, 192)    215040      ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 4, 4, 192)    147456      ['average_pooling2d_4[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 4, 4, 192)   576         ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 4, 4, 192)   576         ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 4, 4, 192)   576         ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 4, 4, 192)   576         ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 4, 4, 192)    0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 4, 4, 192)    0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 4, 4, 192)    0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 4, 4, 192)    0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 4, 4, 768)    0           ['activation_40[0][0]',          \n",
      "                                                                  'activation_43[0][0]',          \n",
      "                                                                  'activation_48[0][0]',          \n",
      "                                                                  'activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 4, 4, 160)    122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 4, 4, 160)   480         ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 4, 4, 160)    0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 4, 4, 160)    179200      ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 4, 4, 160)   480         ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 4, 4, 160)    0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 4, 4, 160)    122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 4, 4, 160)    179200      ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 4, 4, 160)   480         ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 4, 4, 160)   480         ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 4, 4, 160)    0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 4, 4, 160)    0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 4, 4, 160)    179200      ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 4, 4, 160)    179200      ['activation_56[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 4, 4, 160)   480         ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 4, 4, 160)   480         ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 4, 4, 160)    0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 4, 4, 160)    0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (AveragePo  (None, 4, 4, 768)   0           ['mixed5[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 4, 4, 192)    147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 4, 4, 192)    215040      ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 4, 4, 192)    215040      ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 4, 4, 192)    147456      ['average_pooling2d_5[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 4, 4, 192)   576         ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 4, 4, 192)   576         ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 4, 4, 192)   576         ['conv2d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 4, 4, 192)   576         ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 4, 4, 192)    0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 4, 4, 192)    0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 4, 4, 192)    0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 4, 4, 192)    0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 4, 4, 768)    0           ['activation_50[0][0]',          \n",
      "                                                                  'activation_53[0][0]',          \n",
      "                                                                  'activation_58[0][0]',          \n",
      "                                                                  'activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 4, 4, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 4, 4, 192)   576         ['conv2d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 4, 4, 192)    0           ['batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 4, 4, 192)    258048      ['activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 4, 4, 192)   576         ['conv2d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 4, 4, 192)    0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 4, 4, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 4, 4, 192)    258048      ['activation_65[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 4, 4, 192)   576         ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 4, 4, 192)   576         ['conv2d_66[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 4, 4, 192)    0           ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 4, 4, 192)    0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 4, 4, 192)    258048      ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 4, 4, 192)    258048      ['activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 4, 4, 192)   576         ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 4, 4, 192)   576         ['conv2d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 4, 4, 192)    0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 4, 4, 192)    0           ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_6 (AveragePo  (None, 4, 4, 768)   0           ['mixed6[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 4, 4, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 4, 4, 192)    258048      ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 4, 4, 192)    258048      ['activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 4, 4, 192)    147456      ['average_pooling2d_6[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 4, 4, 192)   576         ['conv2d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 4, 4, 192)   576         ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 4, 4, 192)   576         ['conv2d_68[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 4, 4, 192)   576         ['conv2d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 4, 4, 192)    0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 4, 4, 192)    0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 4, 4, 192)    0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 4, 4, 192)    0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 4, 4, 768)    0           ['activation_60[0][0]',          \n",
      "                                                                  'activation_63[0][0]',          \n",
      "                                                                  'activation_68[0][0]',          \n",
      "                                                                  'activation_69[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 4, 4, 192)    147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 4, 4, 192)   576         ['conv2d_72[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, 4, 4, 192)    0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 4, 4, 192)    258048      ['activation_72[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 4, 4, 192)   576         ['conv2d_73[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_73 (Activation)     (None, 4, 4, 192)    0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 4, 4, 192)    147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 4, 4, 192)    258048      ['activation_73[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 4, 4, 192)   576         ['conv2d_70[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 4, 4, 192)   576         ['conv2d_74[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_70 (Activation)     (None, 4, 4, 192)    0           ['batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " activation_74 (Activation)     (None, 4, 4, 192)    0           ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 1, 1, 320)    552960      ['activation_70[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 1, 1, 192)    331776      ['activation_74[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 1, 1, 320)   960         ['conv2d_71[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 1, 1, 192)   576         ['conv2d_75[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_71 (Activation)     (None, 1, 1, 320)    0           ['batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " activation_75 (Activation)     (None, 1, 1, 192)    0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 768)   0           ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)           (None, 1, 1, 1280)   0           ['activation_71[0][0]',          \n",
      "                                                                  'activation_75[0][0]',          \n",
      "                                                                  'max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 1, 1, 448)    573440      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 1, 1, 448)   1344        ['conv2d_80[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_80 (Activation)     (None, 1, 1, 448)    0           ['batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 1, 1, 384)    491520      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 1, 1, 384)    1548288     ['activation_80[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_77[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_81[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_77 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " activation_81 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 1, 1, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 1, 1, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 1, 1, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 1, 1, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_7 (AveragePo  (None, 1, 1, 1280)  0           ['mixed8[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 1, 1, 320)    409600      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_78[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_79[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_82[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_83[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 1, 1, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 1, 1, 320)   960         ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_78 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " activation_79 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 1, 1, 192)   576         ['conv2d_84[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_76 (Activation)     (None, 1, 1, 320)    0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)         (None, 1, 1, 768)    0           ['activation_78[0][0]',          \n",
      "                                                                  'activation_79[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 1, 1, 768)    0           ['activation_82[0][0]',          \n",
      "                                                                  'activation_83[0][0]']          \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, 1, 1, 192)    0           ['batch_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)           (None, 1, 1, 2048)   0           ['activation_76[0][0]',          \n",
      "                                                                  'mixed9_0[0][0]',               \n",
      "                                                                  'concatenate[0][0]',            \n",
      "                                                                  'activation_84[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 1, 1, 448)    917504      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 1, 1, 448)   1344        ['conv2d_89[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_89 (Activation)     (None, 1, 1, 448)    0           ['batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 1, 1, 384)    786432      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 1, 1, 384)    1548288     ['activation_89[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_86[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_90[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_86 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " activation_90 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 1, 1, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 1, 1, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 1, 1, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 1, 1, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_8 (AveragePo  (None, 1, 1, 2048)  0           ['mixed9[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 1, 1, 320)    655360      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_87[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_88[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_91[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_92[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 1, 1, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 1, 1, 320)   960         ['conv2d_85[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_87 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " activation_88 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " activation_91 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " activation_92 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 1, 1, 192)   576         ['conv2d_93[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_85 (Activation)     (None, 1, 1, 320)    0           ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)         (None, 1, 1, 768)    0           ['activation_87[0][0]',          \n",
      "                                                                  'activation_88[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 1, 1, 768)    0           ['activation_91[0][0]',          \n",
      "                                                                  'activation_92[0][0]']          \n",
      "                                                                                                  \n",
      " activation_93 (Activation)     (None, 1, 1, 192)    0           ['batch_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)          (None, 1, 1, 2048)   0           ['activation_85[0][0]',          \n",
      "                                                                  'mixed9_1[0][0]',               \n",
      "                                                                  'concatenate_1[0][0]',          \n",
      "                                                                  'activation_93[0][0]']          \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 2048)        0           ['mixed10[0][0]']                \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          262272      ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 21)           2709        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 22,067,765\n",
      "Trainable params: 264,981\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/teresabono/miniconda3/envs/re-prods/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 2.4794 - accuracy: 0.2500 - val_loss: 3.5124 - val_accuracy: 0.0312\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.5384 - accuracy: 0.6562 - val_loss: 3.6256 - val_accuracy: 0.0312\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0469 - accuracy: 0.7188 - val_loss: 3.7082 - val_accuracy: 0.0312\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6893 - accuracy: 0.8750 - val_loss: 3.7868 - val_accuracy: 0.0625\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4375 - accuracy: 0.9375 - val_loss: 3.8907 - val_accuracy: 0.0625\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2819 - accuracy: 1.0000 - val_loss: 3.9999 - val_accuracy: 0.0938\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1872 - accuracy: 1.0000 - val_loss: 4.0969 - val_accuracy: 0.0938\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1279 - accuracy: 1.0000 - val_loss: 4.1937 - val_accuracy: 0.0625\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0903 - accuracy: 1.0000 - val_loss: 4.2876 - val_accuracy: 0.0625\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0654 - accuracy: 1.0000 - val_loss: 4.3865 - val_accuracy: 0.0625\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0482 - accuracy: 1.0000 - val_loss: 4.4931 - val_accuracy: 0.0625\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0358 - accuracy: 1.0000 - val_loss: 4.6028 - val_accuracy: 0.0625\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 4.7083 - val_accuracy: 0.0625\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 4.8115 - val_accuracy: 0.0625\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 4.9078 - val_accuracy: 0.0625\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 4.9967 - val_accuracy: 0.0625\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 5.0792 - val_accuracy: 0.0312\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 5.1513 - val_accuracy: 0.0312\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 5.2176 - val_accuracy: 0.0312\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 5.2787 - val_accuracy: 0.0312\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 5.3354 - val_accuracy: 0.0312\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 5.3881 - val_accuracy: 0.0312\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 5.4366 - val_accuracy: 0.0312\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 5.4815 - val_accuracy: 0.0312\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 5.5232 - val_accuracy: 0.0312\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 5.5615 - val_accuracy: 0.0312\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 5.5972 - val_accuracy: 0.0312\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 9.9957e-04 - accuracy: 1.0000 - val_loss: 5.6303 - val_accuracy: 0.0312\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 8.9538e-04 - accuracy: 1.0000 - val_loss: 5.6608 - val_accuracy: 0.0312\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 8.0967e-04 - accuracy: 1.0000 - val_loss: 5.6890 - val_accuracy: 0.0312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe96aa8b190>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "train_images = train['images'] / 255.0\n",
    "val_images = val['images'] / 255.0\n",
    "\n",
    "train_lables =  train['labels']\n",
    "val_labels = val['labels']\n",
    "\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "model.fit(train_images, train_lables,\n",
    "          epochs=Config.EPOCHS,\n",
    "          validation_data=(val_images, val_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train['images'] / 255.0\n",
    "val_images = val['images'] / 255.0\n",
    "\n",
    "train_lables =  train['labels']\n",
    "val_labels = val['labels']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.core.protobuf.error_codes_pb2' has no attribute '_CODE'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/teresabono/Documents/UCL/Task/kaggle-retail-prods/experminet_dual_encoder.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/teresabono/Documents/UCL/Task/kaggle-retail-prods/experminet_dual_encoder.ipynb#X36sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Model\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/teresabono/Documents/UCL/Task/kaggle-retail-prods/experminet_dual_encoder.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizers\u001b[39;00m \u001b[39mimport\u001b[39;00m Adam\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/teresabono/Documents/UCL/Task/kaggle-retail-prods/experminet_dual_encoder.ipynb#X36sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow_hub\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mhub\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/teresabono/Documents/UCL/Task/kaggle-retail-prods/experminet_dual_encoder.ipynb#X36sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/teresabono/Documents/UCL/Task/kaggle-retail-prods/experminet_dual_encoder.ipynb#X36sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Load the pre-trained image model\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/re-prods/lib/python3.10/site-packages/tensorflow_hub/__init__.py:29\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[39m# Only do imports after check TensorFlow version so the useful\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[39m# error message is thrown instead of an obscure error of missing\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[39m# symbols at executing the imports.\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_hub\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mestimator\u001b[39;00m \u001b[39mimport\u001b[39;00m LatestModuleExporter\n\u001b[1;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_hub\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mestimator\u001b[39;00m \u001b[39mimport\u001b[39;00m register_module_for_export\n\u001b[1;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_hub\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_column\u001b[39;00m \u001b[39mimport\u001b[39;00m image_embedding_column\n",
      "File \u001b[0;32m~/miniconda3/envs/re-prods/lib/python3.10/site-packages/tensorflow_hub/estimator.py:64\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     59\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mThere is already a module registered to be exported as \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     60\u001b[0m           \u001b[39m%\u001b[39m export_name)\n\u001b[1;32m     61\u001b[0m   tf_v1\u001b[39m.\u001b[39madd_to_collection(_EXPORT_MODULES_COLLECTION, (export_name, module))\n\u001b[0;32m---> 64\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mLatestModuleExporter\u001b[39;00m(tf_v1\u001b[39m.\u001b[39;49mestimator\u001b[39m.\u001b[39;49mExporter):\n\u001b[1;32m     65\u001b[0m   \u001b[39m\"\"\"Regularly exports registered modules into timestamped directories.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \n\u001b[1;32m     67\u001b[0m \u001b[39m  DEPRECATION NOTE: This belongs to the hub.Module API and file format for TF1.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39m  See `LatestModuleExporter.export()` for a direct use example.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m     91\u001b[0m   \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, serving_input_fn, exports_to_keep\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/re-prods/lib/python3.10/site-packages/tensorflow/python/util/lazy_loader.py:58\u001b[0m, in \u001b[0;36mLazyLoader.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, item):\n\u001b[0;32m---> 58\u001b[0m   module \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load()\n\u001b[1;32m     59\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(module, item)\n",
      "File \u001b[0;32m~/miniconda3/envs/re-prods/lib/python3.10/site-packages/tensorflow/python/util/lazy_loader.py:41\u001b[0m, in \u001b[0;36mLazyLoader._load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39m# Import the target module and insert it into the parent's namespace\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m module \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mimport_module(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m)\n\u001b[1;32m     42\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent_module_globals[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_local_name] \u001b[39m=\u001b[39m module\n\u001b[1;32m     44\u001b[0m \u001b[39m# Emit a warning if one was specified\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/re-prods/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m~/miniconda3/envs/re-prods/lib/python3.10/site-packages/tensorflow_estimator/__init__.py:8\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39m\"\"\"Public API for tf. namespace.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_estimator\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv1\u001b[39;00m \u001b[39mimport\u001b[39;00m estimator\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m module_wrapper \u001b[39mas\u001b[39;00m _module_wrapper\n\u001b[1;32m     11\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(_sys\u001b[39m.\u001b[39mmodules[\u001b[39m__name__\u001b[39m], _module_wrapper\u001b[39m.\u001b[39mTFModuleWrapper):\n",
      "File \u001b[0;32m~/miniconda3/envs/re-prods/lib/python3.10/site-packages/tensorflow_estimator/_api/v1/estimator/__init__.py:11\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_estimator\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv1\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mestimator\u001b[39;00m \u001b[39mimport\u001b[39;00m export\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_estimator\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv1\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mestimator\u001b[39;00m \u001b[39mimport\u001b[39;00m inputs\n\u001b[0;32m---> 11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_estimator\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv1\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mestimator\u001b[39;00m \u001b[39mimport\u001b[39;00m tpu\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_estimator\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mestimator\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcanned\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbaseline\u001b[39;00m \u001b[39mimport\u001b[39;00m BaselineClassifier\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_estimator\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mestimator\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcanned\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbaseline\u001b[39;00m \u001b[39mimport\u001b[39;00m BaselineEstimator\n",
      "File \u001b[0;32m~/miniconda3/envs/re-prods/lib/python3.10/site-packages/tensorflow_estimator/_api/v1/estimator/tpu/__init__.py:12\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_estimator\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mestimator\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtpu\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtpu_config\u001b[39;00m \u001b[39mimport\u001b[39;00m RunConfig\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_estimator\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mestimator\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtpu\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtpu_config\u001b[39;00m \u001b[39mimport\u001b[39;00m TPUConfig\n\u001b[0;32m---> 12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_estimator\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mestimator\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtpu\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtpu_estimator\u001b[39;00m \u001b[39mimport\u001b[39;00m TPUEstimator\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_estimator\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mestimator\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtpu\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtpu_estimator\u001b[39;00m \u001b[39mimport\u001b[39;00m TPUEstimatorSpec\n\u001b[1;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m module_wrapper \u001b[39mas\u001b[39;00m _module_wrapper\n",
      "File \u001b[0;32m~/miniconda3/envs/re-prods/lib/python3.10/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:39\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m variable_pb2\n\u001b[1;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msummary_pb2\u001b[39;00m \u001b[39mimport\u001b[39;00m Summary\n\u001b[0;32m---> 39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprotobuf\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtpu\u001b[39;00m \u001b[39mimport\u001b[39;00m compilation_result_pb2 \u001b[39mas\u001b[39;00m tpu_compilation_result\n\u001b[1;32m     40\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m nest \u001b[39mas\u001b[39;00m data_nest\n\u001b[1;32m     41\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistribute\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcluster_resolver\u001b[39;00m \u001b[39mimport\u001b[39;00m tpu_cluster_resolver\n",
      "File \u001b[0;32m~/miniconda3/envs/re-prods/lib/python3.10/site-packages/tensorflow/core/protobuf/tpu/compilation_result_pb2.py:106\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m _sym_db\u001b[39m.\u001b[39mRegisterEnumDescriptor(_COMPILATIONRESULTPROTO_ERRORCODE)\n\u001b[1;32m     54\u001b[0m _COMPILATIONRESULTPROTO \u001b[39m=\u001b[39m _descriptor\u001b[39m.\u001b[39mDescriptor(\n\u001b[1;32m     55\u001b[0m   name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCompilationResultProto\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     56\u001b[0m   full_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensorflow.tpu.CompilationResultProto\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    103\u001b[0m   serialized_end\u001b[39m=\u001b[39m\u001b[39m410\u001b[39m,\n\u001b[1;32m    104\u001b[0m )\n\u001b[0;32m--> 106\u001b[0m _COMPILATIONRESULTPROTO\u001b[39m.\u001b[39mfields_by_name[\u001b[39m'\u001b[39m\u001b[39mstatus_code\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39menum_type \u001b[39m=\u001b[39m tensorflow_dot_core_dot_protobuf_dot_error__codes__pb2\u001b[39m.\u001b[39;49m_CODE\n\u001b[1;32m    107\u001b[0m _COMPILATIONRESULTPROTO\u001b[39m.\u001b[39mfields_by_name[\u001b[39m'\u001b[39m\u001b[39mhlo_protos\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmessage_type \u001b[39m=\u001b[39m tensorflow_dot_compiler_dot_xla_dot_service_dot_hlo__pb2\u001b[39m.\u001b[39m_HLOPROTO\n\u001b[1;32m    108\u001b[0m _COMPILATIONRESULTPROTO\u001b[39m.\u001b[39mfields_by_name[\u001b[39m'\u001b[39m\u001b[39merror_code\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39menum_type \u001b[39m=\u001b[39m _COMPILATIONRESULTPROTO_ERRORCODE\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.core.protobuf.error_codes_pb2' has no attribute '_CODE'"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Dropout, Flatten, concatenate\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the pre-trained image model\n",
    "image_model = tf.keras.Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/5\", trainable=False),\n",
    "    Dropout(0.5),\n",
    "    Dense(512, activation='relu')\n",
    "])\n",
    "\n",
    "# Load the pre-trained language model\n",
    "text_model = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\", trainable=False)\n",
    "\n",
    "# Define the joint embedding model\n",
    "image_input = Input(shape=(Config.IMG_HEIGHT, Config.IMG_WIDTH, 3))\n",
    "text_input = Input(shape=(), dtype=tf.string)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit([train_images, train_text], train_labels, batch_size=32, epochs=10, validation_data=([val_images, val_text], val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate([test_images, test_text], test_labels, batch_size=32)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the pre-trained CLIP model\n",
    "model, preprocess = clip.load('ViT-B/32', device='cpu')\n",
    "\n",
    "# Freeze the model's parameters\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Define the new classification head\n",
    "input_image = Input(shape=(224, 224, 3))\n",
    "input_text = Input(shape=(1,))\n",
    "image_features = model.layers[3](input_image)\n",
    "text_features = model.layers[4](input_text)\n",
    "features = Concatenate()([image_features, text_features])\n",
    "logits = Dense(units=10, activation='softmax')(features)\n",
    "classifier = Model(inputs=[input_image, input_text], outputs=logits)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = \n",
    "\n",
    "# Define a custom dataset for your image-text pairs\n",
    "class ImageTextDataset(tf.keras.utils.Sequence):\n",
    "    def __init__(self, images, texts, labels, batch_size):\n",
    "        self.images = images\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.labels) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_images = self.image[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_texts = self.texts[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_labels = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_images =  batch_images / 255.0\n",
    "        batch_images = np.array(batch_images)\n",
    "        batch_texts = np.array(batch_texts)\n",
    "\n",
    "        return [batch_images, batch_texts], batch_labels\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Create the training and validation datasets\n",
    "train_dataset = ImageTextDataset(train_images, train_texts, train_labels, BATCH_SIZE)\n",
    "val_dataset = ImageTextDataset(val_images, val_texts, val_labels, BATCH_SIZE)\n",
    "\n",
    "# Train the model\n",
    "classifier.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
    "history = classifier.fit(train_dataset, epochs=Config.EPOCHS, validation_data=val_dataset)\n",
    "\n",
    "# Plot the training and validation accuracy curves\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'], label='Training accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the pre-trained CLIP model\n",
    "model, preprocess = clip.load('ViT-B/32', device='cpu')\n",
    "\n",
    "# Freeze the model's parameters\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Define the new classification head\n",
    "input_image = Input(shape=(224, 224, 3))\n",
    "input_text = Input(shape=(1,))\n",
    "image_features = model.layers[3](input_image)\n",
    "text_features = model.layers[4](input_text)\n",
    "features = Concatenate()([image_features, text_features])\n",
    "logits = Dense(units=10, activation='softmax')(features)\n",
    "classifier = Model(inputs=[input_image, input_text], outputs=logits)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = Adam(lr=0.001)\n",
    "\n",
    "# Define a custom dataset for your image-text pairs\n",
    "class MyDataset(tf.keras.utils.Sequence):\n",
    "    def __init__(self, image_paths, texts, labels, batch_size):\n",
    "        self.image_paths = image_paths\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.labels) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_image_paths = self.image_paths[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_texts = self.texts[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_labels = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_images = [preprocess(Image.open(image_path).convert('RGB')) for image_path in batch_image_paths]\n",
    "        batch_images = np.array(batch_images)\n",
    "        batch_texts = np.array(batch_texts)\n",
    "\n",
    "        return [batch_images, batch_texts], batch_labels\n",
    "\n",
    "# Prepare your image-text pairs\n",
    "image_paths = [...] # list of image paths\n",
    "texts = [...] # list of text descriptions\n",
    "labels = [...] # list of labels\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_image_paths, val_image_paths, train_texts, val_texts, train_labels, val_labels = train_test_split(image_paths, texts, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Create the training and validation datasets\n",
    "train_dataset = MyDataset(train_image_paths, train_texts, train_labels, batch_size)\n",
    "val_dataset = MyDataset(val_image_paths, val_texts, val_labels, batch_size)\n",
    "\n",
    "# Train the model\n",
    "classifier.compile(optimizer=optimizer, loss=criterion, metrics=['accuracy'])\n",
    "history = classifier.fit(train_dataset, epochs=10, validation_data=val_dataset)\n",
    "\n",
    "# Plot the training and validation accuracy curves\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'], label='Training accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "re-prods",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
